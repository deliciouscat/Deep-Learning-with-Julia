{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `@pyimport foo` is deprecated in favor of `foo = pyimport(\"foo\")`.\n",
      "│   caller = _pywrap_pyimport(::PyObject) at PyCall.jl:399\n",
      "└ @ PyCall C:\\Users\\Sunmo Koo\\.julia\\packages\\PyCall\\zqDXB\\src\\PyCall.jl:399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <function fetch_openml at 0x000000005B8485E0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using Plots\n",
    "#using Flux.Data\n",
    "using PyCall\n",
    "@pyimport pickle\n",
    "@pyimport numpy as np\n",
    "using ScikitLearn\n",
    "@sk_import datasets: fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " y = 0   if  w1x1 + w2x2 ≤ θ\n",
    "\n",
    "   = 1   if  w1x1 + w2x2 > θ\n",
    "\n",
    "θ = -b로 아래와 같이 치환 가능\n",
    "\n",
    " y = 0   if  b + w1x1 + w2x2 ≤ 0\n",
    " \n",
    "   = 1   if  b + w1x1 + w2x2 > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AND (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function AND(x1,x2)\n",
    "    x = [x1 x2]\n",
    "    w = [0.5 0.5]       # w1 = w2 ≤ theta\n",
    "    b = -0.6\n",
    "    tmp = dot(x,w) + b\n",
    "    if tmp <= 0\n",
    "        return 0\n",
    "    elseif tmp > 0             # 0.5를 넘으면 1, 못넘으면 0 반환\n",
    "        return 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAND (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function NAND(x1,x2)\n",
    "    x = [x1 x2]\n",
    "    w = [-0.5 -0.5]        # AND 게이트의 것을 부호반전 시키면 된다.\n",
    "    b = 0.6\n",
    "    tmp = dot(x,w) + b\n",
    "    if tmp <= 0\n",
    "        return 0\n",
    "    elseif tmp > 0\n",
    "        return 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OR (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function OR(x1, x2)\n",
    "    x = [x1 x2]\n",
    "    w = [0.5 0.5]\n",
    "    b = -0.3              # w1 = w2 > theta\n",
    "    tmp = dot(w,x) + b\n",
    "    if tmp <= 0\n",
    "        return 0\n",
    "    else\n",
    "        return 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XOR (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function XOR(x1, x2)\n",
    "    s1 = NAND(x1, x2)\n",
    "    s2 = OR(x1, x2)\n",
    "    y = AND(s1, s2)\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOR(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph 도식에서, 노드는 x, 화살표는 w값을 가진다.\n",
    "\n",
    "$x_k$노드에서 $w_k$가중치(화살표)로 결과값 y를 구하는 경우 : \n",
    "$a=w_1x_1+w_2x_2+b$\n",
    "\n",
    "$b$는 편향이다. 값이 항상 1로 고정된 노드에서 출발한다고 생각해도 됨.\n",
    "\n",
    "퍼셉트론은 이진분류를 한다 : $y=\\begin{matrix}0 & if\\quad a\\le0\\\\1 & if\\quad a>0\\end{matrix}$\n",
    "\n",
    "이진분류하는 퍼셉트론이 아닌 Sigmoid 등의 함수로 대체할 수 있다. \n",
    "\n",
    "$$y=h(a=w_1x_1+w_2x_2+b)$$\n",
    "### 시그모이드 함수 :\n",
    "$$h(x)=\\frac{1}{1+exp(-x)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relu (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계단함수 구현\n",
    "function step_function(x)\n",
    "    if x>0\n",
    "        return 1\n",
    "    else\n",
    "        return 0\n",
    "    end\n",
    "end\n",
    "\n",
    "# 이렇게도 가능하다.\n",
    "function step_function(x)\n",
    "    y = map(a -> convert(Int64,a>0), x)\n",
    "    return y\n",
    "end\n",
    "\n",
    "# 시그모이드\n",
    "function sigmoid(x)\n",
    "    return map(a -> 1/(1+exp(-a)), x)\n",
    "end\n",
    "\n",
    "# ReLU\n",
    "function relu(x)\n",
    "    return map(a -> maximum([0,0.3a]), x)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip0500\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip0500)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip0501\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip0500)\" d=\"\n",
       "M174.862 1486.45 L2352.76 1486.45 L2352.76 123.472 L174.862 123.472  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip0502\">\n",
       "    <rect x=\"174\" y=\"123\" width=\"2179\" height=\"1364\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  441.962,1486.45 441.962,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  852.886,1486.45 852.886,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1263.81,1486.45 1263.81,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1674.73,1486.45 1674.73,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2085.66,1486.45 2085.66,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,1372.87 2352.76,1372.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,1088.91 2352.76,1088.91 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,804.96 2352.76,804.96 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,521.007 2352.76,521.007 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,237.053 2352.76,237.053 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1486.45 174.862,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  441.962,1486.45 441.962,1470.09 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  852.886,1486.45 852.886,1470.09 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1263.81,1486.45 1263.81,1470.09 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1674.73,1486.45 1674.73,1470.09 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2085.66,1486.45 2085.66,1470.09 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1372.87 200.997,1372.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1088.91 200.997,1088.91 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,804.96 200.997,804.96 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,521.007 200.997,521.007 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,237.053 200.997,237.053 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0500)\" d=\"M 0 0 M421.974 1525.04 L434.451 1525.04 L434.451 1528.83 L421.974 1528.83 L421.974 1525.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M452.367 1509.43 L440.562 1527.88 L452.367 1527.88 L452.367 1509.43 M451.14 1505.36 L457.02 1505.36 L457.02 1527.88 L461.951 1527.88 L461.951 1531.77 L457.02 1531.77 L457.02 1539.92 L452.367 1539.92 L452.367 1531.77 L436.765 1531.77 L436.765 1527.26 L451.14 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M833.939 1525.04 L846.416 1525.04 L846.416 1528.83 L833.939 1528.83 L833.939 1525.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M855.513 1535.98 L871.832 1535.98 L871.832 1539.92 L849.888 1539.92 L849.888 1535.98 Q852.55 1533.23 857.133 1528.6 Q861.74 1523.95 862.92 1522.61 Q865.166 1520.08 866.045 1518.35 Q866.948 1516.59 866.948 1514.9 Q866.948 1512.14 865.004 1510.41 Q863.082 1508.67 859.98 1508.67 Q857.781 1508.67 855.328 1509.43 Q852.897 1510.2 850.119 1511.75 L850.119 1507.03 Q852.943 1505.89 855.397 1505.31 Q857.851 1504.73 859.888 1504.73 Q865.258 1504.73 868.453 1507.42 Q871.647 1510.11 871.647 1514.6 Q871.647 1516.73 870.837 1518.65 Q870.05 1520.54 867.943 1523.14 Q867.365 1523.81 864.263 1527.03 Q861.161 1530.22 855.513 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1263.81 1508.44 Q1260.2 1508.44 1258.37 1512 Q1256.56 1515.55 1256.56 1522.67 Q1256.56 1529.78 1258.37 1533.35 Q1260.2 1536.89 1263.81 1536.89 Q1267.44 1536.89 1269.25 1533.35 Q1271.08 1529.78 1271.08 1522.67 Q1271.08 1515.55 1269.25 1512 Q1267.44 1508.44 1263.81 1508.44 M1263.81 1504.73 Q1269.62 1504.73 1272.67 1509.34 Q1275.75 1513.92 1275.75 1522.67 Q1275.75 1531.4 1272.67 1536.01 Q1269.62 1540.59 1263.81 1540.59 Q1258 1540.59 1254.92 1536.01 Q1251.86 1531.4 1251.86 1522.67 Q1251.86 1513.92 1254.92 1509.34 Q1258 1504.73 1263.81 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1669.39 1535.98 L1685.7 1535.98 L1685.7 1539.92 L1663.76 1539.92 L1663.76 1535.98 Q1666.42 1533.23 1671.01 1528.6 Q1675.61 1523.95 1676.79 1522.61 Q1679.04 1520.08 1679.92 1518.35 Q1680.82 1516.59 1680.82 1514.9 Q1680.82 1512.14 1678.88 1510.41 Q1676.95 1508.67 1673.85 1508.67 Q1671.65 1508.67 1669.2 1509.43 Q1666.77 1510.2 1663.99 1511.75 L1663.99 1507.03 Q1666.82 1505.89 1669.27 1505.31 Q1671.72 1504.73 1673.76 1504.73 Q1679.13 1504.73 1682.32 1507.42 Q1685.52 1510.11 1685.52 1514.6 Q1685.52 1516.73 1684.71 1518.65 Q1683.92 1520.54 1681.82 1523.14 Q1681.24 1523.81 1678.14 1527.03 Q1675.03 1530.22 1669.39 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M2088.66 1509.43 L2076.86 1527.88 L2088.66 1527.88 L2088.66 1509.43 M2087.44 1505.36 L2093.32 1505.36 L2093.32 1527.88 L2098.25 1527.88 L2098.25 1531.77 L2093.32 1531.77 L2093.32 1539.92 L2088.66 1539.92 L2088.66 1531.77 L2073.06 1531.77 L2073.06 1527.26 L2087.44 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M74.9365 1358.67 Q71.3254 1358.67 69.4967 1362.23 Q67.6912 1365.77 67.6912 1372.9 Q67.6912 1380.01 69.4967 1383.57 Q71.3254 1387.11 74.9365 1387.11 Q78.5707 1387.11 80.3763 1383.57 Q82.205 1380.01 82.205 1372.9 Q82.205 1365.77 80.3763 1362.23 Q78.5707 1358.67 74.9365 1358.67 M74.9365 1354.96 Q80.7467 1354.96 83.8022 1359.57 Q86.8809 1364.15 86.8809 1372.9 Q86.8809 1381.63 83.8022 1386.23 Q80.7467 1390.82 74.9365 1390.82 Q69.1264 1390.82 66.0477 1386.23 Q62.9921 1381.63 62.9921 1372.9 Q62.9921 1364.15 66.0477 1359.57 Q69.1264 1354.96 74.9365 1354.96 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M91.9503 1384.27 L96.8345 1384.27 L96.8345 1390.15 L91.9503 1390.15 L91.9503 1384.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M111.904 1358.67 Q108.293 1358.67 106.464 1362.23 Q104.659 1365.77 104.659 1372.9 Q104.659 1380.01 106.464 1383.57 Q108.293 1387.11 111.904 1387.11 Q115.538 1387.11 117.344 1383.57 Q119.172 1380.01 119.172 1372.9 Q119.172 1365.77 117.344 1362.23 Q115.538 1358.67 111.904 1358.67 M111.904 1354.96 Q117.714 1354.96 120.77 1359.57 Q123.848 1364.15 123.848 1372.9 Q123.848 1381.63 120.77 1386.23 Q117.714 1390.82 111.904 1390.82 Q106.094 1390.82 103.015 1386.23 Q99.9595 1381.63 99.9595 1372.9 Q99.9595 1364.15 103.015 1359.57 Q106.094 1354.96 111.904 1354.96 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M138.918 1358.67 Q135.307 1358.67 133.478 1362.23 Q131.672 1365.77 131.672 1372.9 Q131.672 1380.01 133.478 1383.57 Q135.307 1387.11 138.918 1387.11 Q142.552 1387.11 144.357 1383.57 Q146.186 1380.01 146.186 1372.9 Q146.186 1365.77 144.357 1362.23 Q142.552 1358.67 138.918 1358.67 M138.918 1354.96 Q144.728 1354.96 147.783 1359.57 Q150.862 1364.15 150.862 1372.9 Q150.862 1381.63 147.783 1386.23 Q144.728 1390.82 138.918 1390.82 Q133.107 1390.82 130.029 1386.23 Q126.973 1381.63 126.973 1372.9 Q126.973 1364.15 130.029 1359.57 Q133.107 1354.96 138.918 1354.96 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M77.5291 1074.71 Q73.918 1074.71 72.0893 1078.28 Q70.2838 1081.82 70.2838 1088.95 Q70.2838 1096.05 72.0893 1099.62 Q73.918 1103.16 77.5291 1103.16 Q81.1633 1103.16 82.9689 1099.62 Q84.7976 1096.05 84.7976 1088.95 Q84.7976 1081.82 82.9689 1078.28 Q81.1633 1074.71 77.5291 1074.71 M77.5291 1071.01 Q83.3392 1071.01 86.3948 1075.61 Q89.4735 1080.2 89.4735 1088.95 Q89.4735 1097.67 86.3948 1102.28 Q83.3392 1106.86 77.5291 1106.86 Q71.7189 1106.86 68.6402 1102.28 Q65.5847 1097.67 65.5847 1088.95 Q65.5847 1080.2 68.6402 1075.61 Q71.7189 1071.01 77.5291 1071.01 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M94.5429 1100.31 L99.4271 1100.31 L99.4271 1106.19 L94.5429 1106.19 L94.5429 1100.31 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M108.524 1102.26 L124.844 1102.26 L124.844 1106.19 L102.899 1106.19 L102.899 1102.26 Q105.561 1099.5 110.145 1094.87 Q114.751 1090.22 115.932 1088.88 Q118.177 1086.36 119.057 1084.62 Q119.959 1082.86 119.959 1081.17 Q119.959 1078.42 118.015 1076.68 Q116.094 1074.94 112.992 1074.94 Q110.793 1074.94 108.339 1075.71 Q105.909 1076.47 103.131 1078.02 L103.131 1073.3 Q105.955 1072.17 108.409 1071.59 Q110.862 1071.01 112.899 1071.01 Q118.27 1071.01 121.464 1073.69 Q124.658 1076.38 124.658 1080.87 Q124.658 1083 123.848 1084.92 Q123.061 1086.82 120.955 1089.41 Q120.376 1090.08 117.274 1093.3 Q114.172 1096.49 108.524 1102.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M129.959 1071.63 L148.316 1071.63 L148.316 1075.57 L134.242 1075.57 L134.242 1084.04 Q135.26 1083.69 136.279 1083.53 Q137.297 1083.35 138.316 1083.35 Q144.103 1083.35 147.482 1086.52 Q150.862 1089.69 150.862 1095.11 Q150.862 1100.68 147.39 1103.79 Q143.918 1106.86 137.598 1106.86 Q135.422 1106.86 133.154 1106.49 Q130.908 1106.12 128.501 1105.38 L128.501 1100.68 Q130.584 1101.82 132.807 1102.37 Q135.029 1102.93 137.506 1102.93 Q141.51 1102.93 143.848 1100.82 Q146.186 1098.72 146.186 1095.11 Q146.186 1091.49 143.848 1089.39 Q141.51 1087.28 137.506 1087.28 Q135.631 1087.28 133.756 1087.7 Q131.904 1088.11 129.959 1088.99 L129.959 1071.63 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M75.9319 790.759 Q72.3208 790.759 70.4921 794.323 Q68.6865 797.865 68.6865 804.995 Q68.6865 812.101 70.4921 815.666 Q72.3208 819.208 75.9319 819.208 Q79.5661 819.208 81.3717 815.666 Q83.2004 812.101 83.2004 804.995 Q83.2004 797.865 81.3717 794.323 Q79.5661 790.759 75.9319 790.759 M75.9319 787.055 Q81.742 787.055 84.7976 791.661 Q87.8763 796.245 87.8763 804.995 Q87.8763 813.722 84.7976 818.328 Q81.742 822.911 75.9319 822.911 Q70.1217 822.911 67.043 818.328 Q63.9875 813.722 63.9875 804.995 Q63.9875 796.245 67.043 791.661 Q70.1217 787.055 75.9319 787.055 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M92.9457 816.36 L97.8299 816.36 L97.8299 822.24 L92.9457 822.24 L92.9457 816.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M102.946 787.68 L121.302 787.68 L121.302 791.615 L107.228 791.615 L107.228 800.087 Q108.247 799.74 109.265 799.578 Q110.284 799.393 111.302 799.393 Q117.089 799.393 120.469 802.564 Q123.848 805.735 123.848 811.152 Q123.848 816.731 120.376 819.833 Q116.904 822.911 110.584 822.911 Q108.409 822.911 106.14 822.541 Q103.895 822.171 101.487 821.43 L101.487 816.731 Q103.571 817.865 105.793 818.421 Q108.015 818.976 110.492 818.976 Q114.496 818.976 116.834 816.87 Q119.172 814.763 119.172 811.152 Q119.172 807.541 116.834 805.435 Q114.496 803.328 110.492 803.328 Q108.617 803.328 106.742 803.745 Q104.89 804.161 102.946 805.041 L102.946 787.68 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M138.918 790.759 Q135.307 790.759 133.478 794.323 Q131.672 797.865 131.672 804.995 Q131.672 812.101 133.478 815.666 Q135.307 819.208 138.918 819.208 Q142.552 819.208 144.357 815.666 Q146.186 812.101 146.186 804.995 Q146.186 797.865 144.357 794.323 Q142.552 790.759 138.918 790.759 M138.918 787.055 Q144.728 787.055 147.783 791.661 Q150.862 796.245 150.862 804.995 Q150.862 813.722 147.783 818.328 Q144.728 822.911 138.918 822.911 Q133.107 822.911 130.029 818.328 Q126.973 813.722 126.973 804.995 Q126.973 796.245 130.029 791.661 Q133.107 787.055 138.918 787.055 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M76.8346 506.805 Q73.2236 506.805 71.3949 510.37 Q69.5893 513.912 69.5893 521.041 Q69.5893 528.148 71.3949 531.713 Q73.2236 535.254 76.8346 535.254 Q80.4689 535.254 82.2744 531.713 Q84.1031 528.148 84.1031 521.041 Q84.1031 513.912 82.2744 510.37 Q80.4689 506.805 76.8346 506.805 M76.8346 503.102 Q82.6448 503.102 85.7003 507.708 Q88.779 512.291 88.779 521.041 Q88.779 529.768 85.7003 534.375 Q82.6448 538.958 76.8346 538.958 Q71.0245 538.958 67.9458 534.375 Q64.8903 529.768 64.8903 521.041 Q64.8903 512.291 67.9458 507.708 Q71.0245 503.102 76.8346 503.102 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M93.8484 532.407 L98.7327 532.407 L98.7327 538.287 L93.8484 538.287 L93.8484 532.407 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M102.622 503.727 L124.844 503.727 L124.844 505.717 L112.297 538.287 L107.413 538.287 L119.219 507.662 L102.622 507.662 L102.622 503.727 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M129.959 503.727 L148.316 503.727 L148.316 507.662 L134.242 507.662 L134.242 516.134 Q135.26 515.787 136.279 515.625 Q137.297 515.44 138.316 515.44 Q144.103 515.44 147.482 518.611 Q150.862 521.782 150.862 527.199 Q150.862 532.777 147.39 535.879 Q143.918 538.958 137.598 538.958 Q135.422 538.958 133.154 538.588 Q130.908 538.217 128.501 537.477 L128.501 532.777 Q130.584 533.912 132.807 534.467 Q135.029 535.023 137.506 535.023 Q141.51 535.023 143.848 532.916 Q146.186 530.81 146.186 527.199 Q146.186 523.588 143.848 521.481 Q141.51 519.375 137.506 519.375 Q135.631 519.375 133.756 519.791 Q131.904 520.208 129.959 521.088 L129.959 503.727 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M66.9736 250.398 L74.6124 250.398 L74.6124 224.033 L66.3023 225.699 L66.3023 221.44 L74.5661 219.773 L79.242 219.773 L79.242 250.398 L86.8809 250.398 L86.8809 254.333 L66.9736 254.333 L66.9736 250.398 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M91.9503 248.454 L96.8345 248.454 L96.8345 254.333 L91.9503 254.333 L91.9503 248.454 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M111.904 222.852 Q108.293 222.852 106.464 226.417 Q104.659 229.959 104.659 237.088 Q104.659 244.195 106.464 247.759 Q108.293 251.301 111.904 251.301 Q115.538 251.301 117.344 247.759 Q119.172 244.195 119.172 237.088 Q119.172 229.959 117.344 226.417 Q115.538 222.852 111.904 222.852 M111.904 219.148 Q117.714 219.148 120.77 223.755 Q123.848 228.338 123.848 237.088 Q123.848 245.815 120.77 250.421 Q117.714 255.005 111.904 255.005 Q106.094 255.005 103.015 250.421 Q99.9595 245.815 99.9595 237.088 Q99.9595 228.338 103.015 223.755 Q106.094 219.148 111.904 219.148 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M138.918 222.852 Q135.307 222.852 133.478 226.417 Q131.672 229.959 131.672 237.088 Q131.672 244.195 133.478 247.759 Q135.307 251.301 138.918 251.301 Q142.552 251.301 144.357 247.759 Q146.186 244.195 146.186 237.088 Q146.186 229.959 144.357 226.417 Q142.552 222.852 138.918 222.852 M138.918 219.148 Q144.728 219.148 147.783 223.755 Q150.862 228.338 150.862 237.088 Q150.862 245.815 147.783 250.421 Q144.728 255.005 138.918 255.005 Q133.107 255.005 130.029 250.421 Q126.973 245.815 126.973 237.088 Q126.973 228.338 130.029 223.755 Q133.107 219.148 138.918 219.148 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M944.76 20.1573 L933.66 50.2555 L955.9 50.2555 L944.76 20.1573 M940.142 12.096 L949.418 12.096 L972.468 72.576 L963.961 72.576 L958.452 57.061 L931.189 57.061 L925.68 72.576 L917.052 72.576 L940.142 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1011.48 28.9478 L1011.48 35.9153 Q1008.32 34.1734 1005.12 33.3227 Q1001.96 32.4315 998.718 32.4315 Q991.467 32.4315 987.456 37.0496 Q983.446 41.6271 983.446 49.9314 Q983.446 58.2358 987.456 62.8538 Q991.467 67.4314 998.718 67.4314 Q1001.96 67.4314 1005.12 66.5807 Q1008.32 65.6895 1011.48 63.9476 L1011.48 70.8341 Q1008.36 72.2924 1005 73.0216 Q1001.67 73.7508 997.908 73.7508 Q987.659 73.7508 981.623 67.3098 Q975.587 60.8689 975.587 49.9314 Q975.587 38.832 981.663 32.472 Q987.78 26.1121 998.394 26.1121 Q1001.84 26.1121 1005.12 26.8413 Q1008.4 27.5299 1011.48 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1026.67 14.324 L1026.67 27.2059 L1042.02 27.2059 L1042.02 32.9987 L1026.67 32.9987 L1026.67 57.6282 Q1026.67 63.1779 1028.17 64.7578 Q1029.71 66.3376 1034.37 66.3376 L1042.02 66.3376 L1042.02 72.576 L1034.37 72.576 Q1025.74 72.576 1022.46 69.3758 Q1019.17 66.1351 1019.17 57.6282 L1019.17 32.9987 L1013.71 32.9987 L1013.71 27.2059 L1019.17 27.2059 L1019.17 14.324 L1026.67 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1049.84 27.2059 L1057.29 27.2059 L1057.29 72.576 L1049.84 72.576 L1049.84 27.2059 M1049.84 9.54393 L1057.29 9.54393 L1057.29 18.9825 L1049.84 18.9825 L1049.84 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1059.76 27.2059 L1067.66 27.2059 L1081.84 65.2844 L1096.02 27.2059 L1103.92 27.2059 L1086.91 72.576 L1076.78 72.576 L1059.76 27.2059 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1132.36 49.7694 Q1123.32 49.7694 1119.84 51.8354 Q1116.36 53.9013 1116.36 58.8839 Q1116.36 62.8538 1118.95 65.2034 Q1121.58 67.5124 1126.08 67.5124 Q1132.28 67.5124 1136 63.1374 Q1139.77 58.7219 1139.77 51.4303 L1139.77 49.7694 L1132.36 49.7694 M1147.22 46.6907 L1147.22 72.576 L1139.77 72.576 L1139.77 65.6895 Q1137.22 69.8214 1133.41 71.8063 Q1129.6 73.7508 1124.09 73.7508 Q1117.13 73.7508 1112.99 69.8619 Q1108.9 65.9325 1108.9 59.3701 Q1108.9 51.7138 1114.01 47.825 Q1119.15 43.9361 1129.32 43.9361 L1139.77 43.9361 L1139.77 43.2069 Q1139.77 38.0623 1136.37 35.2672 Q1133.01 32.4315 1126.89 32.4315 Q1123 32.4315 1119.31 33.3632 Q1115.63 34.295 1112.22 36.1584 L1112.22 29.2718 Q1116.32 27.692 1120.16 26.9223 Q1124.01 26.1121 1127.66 26.1121 Q1137.5 26.1121 1142.36 31.2163 Q1147.22 36.3204 1147.22 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1162.41 14.324 L1162.41 27.2059 L1177.77 27.2059 L1177.77 32.9987 L1162.41 32.9987 L1162.41 57.6282 Q1162.41 63.1779 1163.91 64.7578 Q1165.45 66.3376 1170.11 66.3376 L1177.77 66.3376 L1177.77 72.576 L1170.11 72.576 Q1161.48 72.576 1158.2 69.3758 Q1154.92 66.1351 1154.92 57.6282 L1154.92 32.9987 L1149.45 32.9987 L1149.45 27.2059 L1154.92 27.2059 L1154.92 14.324 L1162.41 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1185.59 27.2059 L1193.04 27.2059 L1193.04 72.576 L1185.59 72.576 L1185.59 27.2059 M1185.59 9.54393 L1193.04 9.54393 L1193.04 18.9825 L1185.59 18.9825 L1185.59 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1218.44 32.4315 Q1212.44 32.4315 1208.96 37.1306 Q1205.48 41.7891 1205.48 49.9314 Q1205.48 58.0738 1208.92 62.7728 Q1212.4 67.4314 1218.44 67.4314 Q1224.39 67.4314 1227.88 62.7323 Q1231.36 58.0333 1231.36 49.9314 Q1231.36 41.8701 1227.88 37.1711 Q1224.39 32.4315 1218.44 32.4315 M1218.44 26.1121 Q1228.16 26.1121 1233.71 32.4315 Q1239.26 38.7509 1239.26 49.9314 Q1239.26 61.0714 1233.71 67.4314 Q1228.16 73.7508 1218.44 73.7508 Q1208.68 73.7508 1203.13 67.4314 Q1197.62 61.0714 1197.62 49.9314 Q1197.62 38.7509 1203.13 32.4315 Q1208.68 26.1121 1218.44 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1284.79 45.1919 L1284.79 72.576 L1277.34 72.576 L1277.34 45.4349 Q1277.34 38.994 1274.83 35.7938 Q1272.32 32.5936 1267.29 32.5936 Q1261.26 32.5936 1257.77 36.4419 Q1254.29 40.2903 1254.29 46.9338 L1254.29 72.576 L1246.8 72.576 L1246.8 27.2059 L1254.29 27.2059 L1254.29 34.2544 Q1256.96 30.163 1260.57 28.1376 Q1264.21 26.1121 1268.95 26.1121 Q1276.77 26.1121 1280.78 30.9732 Q1284.79 35.7938 1284.79 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1341.95 9.54393 L1341.95 15.7418 L1334.82 15.7418 Q1330.81 15.7418 1329.23 17.3622 Q1327.69 18.9825 1327.69 23.1955 L1327.69 27.2059 L1339.97 27.2059 L1339.97 32.9987 L1327.69 32.9987 L1327.69 72.576 L1320.2 72.576 L1320.2 32.9987 L1313.07 32.9987 L1313.07 27.2059 L1320.2 27.2059 L1320.2 24.0462 Q1320.2 16.471 1323.72 13.0277 Q1327.25 9.54393 1334.9 9.54393 L1341.95 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1349 54.671 L1349 27.2059 L1356.45 27.2059 L1356.45 54.3874 Q1356.45 60.8284 1358.96 64.0691 Q1361.48 67.2693 1366.5 67.2693 Q1372.54 67.2693 1376.02 63.421 Q1379.54 59.5726 1379.54 52.9291 L1379.54 27.2059 L1387 27.2059 L1387 72.576 L1379.54 72.576 L1379.54 65.6084 Q1376.83 69.7404 1373.22 71.7658 Q1369.66 73.7508 1364.92 73.7508 Q1357.1 73.7508 1353.05 68.8897 Q1349 64.0286 1349 54.671 M1367.76 26.1121 L1367.76 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1432.53 45.1919 L1432.53 72.576 L1425.08 72.576 L1425.08 45.4349 Q1425.08 38.994 1422.56 35.7938 Q1420.05 32.5936 1415.03 32.5936 Q1408.99 32.5936 1405.51 36.4419 Q1402.03 40.2903 1402.03 46.9338 L1402.03 72.576 L1394.53 72.576 L1394.53 27.2059 L1402.03 27.2059 L1402.03 34.2544 Q1404.7 30.163 1408.3 28.1376 Q1411.95 26.1121 1416.69 26.1121 Q1424.51 26.1121 1428.52 30.9732 Q1432.53 35.7938 1432.53 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1473 28.9478 L1473 35.9153 Q1469.84 34.1734 1466.64 33.3227 Q1463.48 32.4315 1460.24 32.4315 Q1452.99 32.4315 1448.98 37.0496 Q1444.97 41.6271 1444.97 49.9314 Q1444.97 58.2358 1448.98 62.8538 Q1452.99 67.4314 1460.24 67.4314 Q1463.48 67.4314 1466.64 66.5807 Q1469.84 65.6895 1473 63.9476 L1473 70.8341 Q1469.88 72.2924 1466.52 73.0216 Q1463.19 73.7508 1459.43 73.7508 Q1449.18 73.7508 1443.14 67.3098 Q1437.11 60.8689 1437.11 49.9314 Q1437.11 38.832 1443.18 32.472 Q1449.3 26.1121 1459.91 26.1121 Q1463.36 26.1121 1466.64 26.8413 Q1469.92 27.5299 1473 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1488.19 14.324 L1488.19 27.2059 L1503.54 27.2059 L1503.54 32.9987 L1488.19 32.9987 L1488.19 57.6282 Q1488.19 63.1779 1489.69 64.7578 Q1491.23 66.3376 1495.89 66.3376 L1503.54 66.3376 L1503.54 72.576 L1495.89 72.576 Q1487.26 72.576 1483.98 69.3758 Q1480.69 66.1351 1480.69 57.6282 L1480.69 32.9987 L1475.23 32.9987 L1475.23 27.2059 L1480.69 27.2059 L1480.69 14.324 L1488.19 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1511.36 27.2059 L1518.81 27.2059 L1518.81 72.576 L1511.36 72.576 L1511.36 27.2059 M1511.36 9.54393 L1518.81 9.54393 L1518.81 18.9825 L1511.36 18.9825 L1511.36 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1544.21 32.4315 Q1538.22 32.4315 1534.73 37.1306 Q1531.25 41.7891 1531.25 49.9314 Q1531.25 58.0738 1534.69 62.7728 Q1538.18 67.4314 1544.21 67.4314 Q1550.17 67.4314 1553.65 62.7323 Q1557.13 58.0333 1557.13 49.9314 Q1557.13 41.8701 1553.65 37.1711 Q1550.17 32.4315 1544.21 32.4315 M1544.21 26.1121 Q1553.93 26.1121 1559.48 32.4315 Q1565.03 38.7509 1565.03 49.9314 Q1565.03 61.0714 1559.48 67.4314 Q1553.93 73.7508 1544.21 73.7508 Q1534.45 73.7508 1528.9 67.4314 Q1523.39 61.0714 1523.39 49.9314 Q1523.39 38.7509 1528.9 32.4315 Q1534.45 26.1121 1544.21 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M1610.57 45.1919 L1610.57 72.576 L1603.11 72.576 L1603.11 45.4349 Q1603.11 38.994 1600.6 35.7938 Q1598.09 32.5936 1593.07 32.5936 Q1587.03 32.5936 1583.55 36.4419 Q1580.06 40.2903 1580.06 46.9338 L1580.06 72.576 L1572.57 72.576 L1572.57 27.2059 L1580.06 27.2059 L1580.06 34.2544 Q1582.74 30.163 1586.34 28.1376 Q1589.99 26.1121 1594.73 26.1121 Q1602.55 26.1121 1606.56 30.9732 Q1610.57 35.7938 1610.57 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip0502)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  236.501,1372.87 244.752,1372.87 253.003,1372.87 261.255,1372.87 269.506,1372.87 277.758,1372.87 286.009,1372.87 294.261,1372.87 302.512,1372.87 310.764,1372.87 \n",
       "  319.015,1372.87 327.267,1372.87 335.518,1372.87 343.77,1372.87 352.021,1372.87 360.273,1372.87 368.524,1372.87 376.776,1372.87 385.027,1372.87 393.279,1372.87 \n",
       "  401.53,1372.87 409.781,1372.87 418.033,1372.87 426.284,1372.87 434.536,1372.87 442.787,1372.87 451.039,1372.87 459.29,1372.87 467.542,1372.87 475.793,1372.87 \n",
       "  484.045,1372.87 492.296,1372.87 500.548,1372.87 508.799,1372.87 517.051,1372.87 525.302,1372.87 533.554,1372.87 541.805,1372.87 550.057,1372.87 558.308,1372.87 \n",
       "  566.559,1372.87 574.811,1372.87 583.062,1372.87 591.314,1372.87 599.565,1372.87 607.817,1372.87 616.068,1372.87 624.32,1372.87 632.571,1372.87 640.823,1372.87 \n",
       "  649.074,1372.87 657.326,1372.87 665.577,1372.87 673.829,1372.87 682.08,1372.87 690.332,1372.87 698.583,1372.87 706.835,1372.87 715.086,1372.87 723.337,1372.87 \n",
       "  731.589,1372.87 739.84,1372.87 748.092,1372.87 756.343,1372.87 764.595,1372.87 772.846,1372.87 781.098,1372.87 789.349,1372.87 797.601,1372.87 805.852,1372.87 \n",
       "  814.104,1372.87 822.355,1372.87 830.607,1372.87 838.858,1372.87 847.11,1372.87 855.361,1372.87 863.613,1372.87 871.864,1372.87 880.115,1372.87 888.367,1372.87 \n",
       "  896.618,1372.87 904.87,1372.87 913.121,1372.87 921.373,1372.87 929.624,1372.87 937.876,1372.87 946.127,1372.87 954.379,1372.87 962.63,1372.87 970.882,1372.87 \n",
       "  979.133,1372.87 987.385,1372.87 995.636,1372.87 1003.89,1372.87 1012.14,1372.87 1020.39,1372.87 1028.64,1372.87 1036.89,1372.87 1045.14,1372.87 1053.4,1372.87 \n",
       "  1061.65,1372.87 1069.9,1372.87 1078.15,1372.87 1086.4,1372.87 1094.65,1372.87 1102.91,1372.87 1111.16,1372.87 1119.41,1372.87 1127.66,1372.87 1135.91,1372.87 \n",
       "  1144.16,1372.87 1152.41,1372.87 1160.67,1372.87 1168.92,1372.87 1177.17,1372.87 1185.42,1372.87 1193.67,1372.87 1201.92,1372.87 1210.17,1372.87 1218.43,1372.87 \n",
       "  1226.68,1372.87 1234.93,1372.87 1243.18,1372.87 1251.43,1372.87 1259.68,1372.87 1267.93,237.053 1276.19,237.053 1284.44,237.053 1292.69,237.053 1300.94,237.053 \n",
       "  1309.19,237.053 1317.44,237.053 1325.7,237.053 1333.95,237.053 1342.2,237.053 1350.45,237.053 1358.7,237.053 1366.95,237.053 1375.2,237.053 1383.46,237.053 \n",
       "  1391.71,237.053 1399.96,237.053 1408.21,237.053 1416.46,237.053 1424.71,237.053 1432.96,237.053 1441.22,237.053 1449.47,237.053 1457.72,237.053 1465.97,237.053 \n",
       "  1474.22,237.053 1482.47,237.053 1490.72,237.053 1498.98,237.053 1507.23,237.053 1515.48,237.053 1523.73,237.053 1531.98,237.053 1540.23,237.053 1548.48,237.053 \n",
       "  1556.74,237.053 1564.99,237.053 1573.24,237.053 1581.49,237.053 1589.74,237.053 1597.99,237.053 1606.25,237.053 1614.5,237.053 1622.75,237.053 1631,237.053 \n",
       "  1639.25,237.053 1647.5,237.053 1655.75,237.053 1664.01,237.053 1672.26,237.053 1680.51,237.053 1688.76,237.053 1697.01,237.053 1705.26,237.053 1713.51,237.053 \n",
       "  1721.77,237.053 1730.02,237.053 1738.27,237.053 1746.52,237.053 1754.77,237.053 1763.02,237.053 1771.27,237.053 1779.53,237.053 1787.78,237.053 1796.03,237.053 \n",
       "  1804.28,237.053 1812.53,237.053 1820.78,237.053 1829.03,237.053 1837.29,237.053 1845.54,237.053 1853.79,237.053 1862.04,237.053 1870.29,237.053 1878.54,237.053 \n",
       "  1886.8,237.053 1895.05,237.053 1903.3,237.053 1911.55,237.053 1919.8,237.053 1928.05,237.053 1936.3,237.053 1944.56,237.053 1952.81,237.053 1961.06,237.053 \n",
       "  1969.31,237.053 1977.56,237.053 1985.81,237.053 1994.06,237.053 2002.32,237.053 2010.57,237.053 2018.82,237.053 2027.07,237.053 2035.32,237.053 2043.57,237.053 \n",
       "  2051.82,237.053 2060.08,237.053 2068.33,237.053 2076.58,237.053 2084.83,237.053 2093.08,237.053 2101.33,237.053 2109.58,237.053 2117.84,237.053 2126.09,237.053 \n",
       "  2134.34,237.053 2142.59,237.053 2150.84,237.053 2159.09,237.053 2167.35,237.053 2175.6,237.053 2183.85,237.053 2192.1,237.053 2200.35,237.053 2208.6,237.053 \n",
       "  2216.85,237.053 2225.11,237.053 2233.36,237.053 2241.61,237.053 2249.86,237.053 2258.11,237.053 2266.36,237.053 2274.61,237.053 2282.87,237.053 2291.12,237.053 \n",
       "  \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  236.501,1365.26 244.752,1364.96 253.003,1364.63 261.255,1364.3 269.506,1363.95 277.758,1363.59 286.009,1363.21 294.261,1362.82 302.512,1362.41 310.764,1361.99 \n",
       "  319.015,1361.55 327.267,1361.09 335.518,1360.61 343.77,1360.11 352.021,1359.6 360.273,1359.06 368.524,1358.5 376.776,1357.92 385.027,1357.31 393.279,1356.69 \n",
       "  401.53,1356.03 409.781,1355.35 418.033,1354.65 426.284,1353.91 434.536,1353.15 442.787,1352.36 451.039,1351.53 459.29,1350.68 467.542,1349.78 475.793,1348.86 \n",
       "  484.045,1347.9 492.296,1346.9 500.548,1345.86 508.799,1344.78 517.051,1343.66 525.302,1342.49 533.554,1341.28 541.805,1340.02 550.057,1338.72 558.308,1337.36 \n",
       "  566.559,1335.96 574.811,1334.49 583.062,1332.98 591.314,1331.4 599.565,1329.77 607.817,1328.07 616.068,1326.31 624.32,1324.48 632.571,1322.59 640.823,1320.62 \n",
       "  649.074,1318.59 657.326,1316.47 665.577,1314.28 673.829,1312.01 682.08,1309.65 690.332,1307.21 698.583,1304.68 706.835,1302.06 715.086,1299.35 723.337,1296.54 \n",
       "  731.589,1293.63 739.84,1290.62 748.092,1287.5 756.343,1284.28 764.595,1280.94 772.846,1277.49 781.098,1273.92 789.349,1270.23 797.601,1266.42 805.852,1262.48 \n",
       "  814.104,1258.42 822.355,1254.22 830.607,1249.88 838.858,1245.41 847.11,1240.79 855.361,1236.03 863.613,1231.12 871.864,1226.07 880.115,1220.86 888.367,1215.49 \n",
       "  896.618,1209.97 904.87,1204.28 913.121,1198.43 921.373,1192.42 929.624,1186.24 937.876,1179.89 946.127,1173.37 954.379,1166.68 962.63,1159.82 970.882,1152.78 \n",
       "  979.133,1145.57 987.385,1138.18 995.636,1130.61 1003.89,1122.87 1012.14,1114.95 1020.39,1106.86 1028.64,1098.59 1036.89,1090.15 1045.14,1081.53 1053.4,1072.75 \n",
       "  1061.65,1063.8 1069.9,1054.68 1078.15,1045.4 1086.4,1035.96 1094.65,1026.37 1102.91,1016.62 1111.16,1006.73 1119.41,996.697 1127.66,986.526 1135.91,976.223 \n",
       "  1144.16,965.795 1152.41,955.247 1160.67,944.587 1168.92,933.821 1177.17,922.956 1185.42,912 1193.67,900.961 1201.92,889.847 1210.17,878.666 1218.43,867.427 \n",
       "  1226.68,856.138 1234.93,844.808 1243.18,833.445 1251.43,822.06 1259.68,810.662 1267.93,799.258 1276.19,787.86 1284.44,776.475 1292.69,765.112 1300.94,753.782 \n",
       "  1309.19,742.493 1317.44,731.254 1325.7,720.073 1333.95,708.959 1342.2,697.92 1350.45,686.964 1358.7,676.099 1366.95,665.333 1375.2,654.673 1383.46,644.125 \n",
       "  1391.71,633.697 1399.96,623.394 1408.21,613.223 1416.46,603.188 1424.71,593.296 1432.96,583.55 1441.22,573.956 1449.47,564.518 1457.72,555.238 1465.97,546.121 \n",
       "  1474.22,537.17 1482.47,528.386 1490.72,519.772 1498.98,511.33 1507.23,503.062 1515.48,494.969 1523.73,487.05 1531.98,479.308 1540.23,471.742 1548.48,464.353 \n",
       "  1556.74,457.139 1564.99,450.1 1573.24,443.236 1581.49,436.545 1589.74,430.027 1597.99,423.678 1606.25,417.499 1614.5,411.487 1622.75,405.639 1631,399.955 \n",
       "  1639.25,394.431 1647.5,389.065 1655.75,383.854 1664.01,378.797 1672.26,373.889 1680.51,369.129 1688.76,364.513 1697.01,360.039 1705.26,355.703 1713.51,351.503 \n",
       "  1721.77,347.436 1730.02,343.498 1738.27,339.686 1746.52,335.998 1754.77,332.43 1763.02,328.98 1771.27,325.643 1779.53,322.418 1787.78,319.301 1796.03,316.289 \n",
       "  1804.28,313.38 1812.53,310.57 1820.78,307.856 1829.03,305.236 1837.29,302.707 1845.54,300.267 1853.79,297.912 1862.04,295.64 1870.29,293.448 1878.54,291.334 \n",
       "  1886.8,289.296 1895.05,287.33 1903.3,285.435 1911.55,283.609 1919.8,281.848 1928.05,280.152 1936.3,278.517 1944.56,276.942 1952.81,275.425 1961.06,273.964 \n",
       "  1969.31,272.556 1977.56,271.201 1985.81,269.895 1994.06,268.639 2002.32,267.428 2010.57,266.263 2018.82,265.142 2027.07,264.063 2035.32,263.024 2043.57,262.024 \n",
       "  2051.82,261.062 2060.08,260.136 2068.33,259.245 2076.58,258.388 2084.83,257.563 2093.08,256.77 2101.33,256.007 2109.58,255.272 2117.84,254.566 2126.09,253.887 \n",
       "  2134.34,253.234 2142.59,252.606 2150.84,252.002 2159.09,251.421 2167.35,250.862 2175.6,250.325 2183.85,249.808 2192.1,249.311 2200.35,248.834 2208.6,248.375 \n",
       "  2216.85,247.933 2225.11,247.509 2233.36,247.101 2241.61,246.709 2249.86,246.332 2258.11,245.97 2266.36,245.621 2274.61,245.286 2282.87,244.965 2291.12,244.655 \n",
       "  \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  236.501,1372.87 244.752,1372.87 253.003,1372.87 261.255,1372.87 269.506,1372.87 277.758,1372.87 286.009,1372.87 294.261,1372.87 302.512,1372.87 310.764,1372.87 \n",
       "  319.015,1372.87 327.267,1372.87 335.518,1372.87 343.77,1372.87 352.021,1372.87 360.273,1372.87 368.524,1372.87 376.776,1372.87 385.027,1372.87 393.279,1372.87 \n",
       "  401.53,1372.87 409.781,1372.87 418.033,1372.87 426.284,1372.87 434.536,1372.87 442.787,1372.87 451.039,1372.87 459.29,1372.87 467.542,1372.87 475.793,1372.87 \n",
       "  484.045,1372.87 492.296,1372.87 500.548,1372.87 508.799,1372.87 517.051,1372.87 525.302,1372.87 533.554,1372.87 541.805,1372.87 550.057,1372.87 558.308,1372.87 \n",
       "  566.559,1372.87 574.811,1372.87 583.062,1372.87 591.314,1372.87 599.565,1372.87 607.817,1372.87 616.068,1372.87 624.32,1372.87 632.571,1372.87 640.823,1372.87 \n",
       "  649.074,1372.87 657.326,1372.87 665.577,1372.87 673.829,1372.87 682.08,1372.87 690.332,1372.87 698.583,1372.87 706.835,1372.87 715.086,1372.87 723.337,1372.87 \n",
       "  731.589,1372.87 739.84,1372.87 748.092,1372.87 756.343,1372.87 764.595,1372.87 772.846,1372.87 781.098,1372.87 789.349,1372.87 797.601,1372.87 805.852,1372.87 \n",
       "  814.104,1372.87 822.355,1372.87 830.607,1372.87 838.858,1372.87 847.11,1372.87 855.361,1372.87 863.613,1372.87 871.864,1372.87 880.115,1372.87 888.367,1372.87 \n",
       "  896.618,1372.87 904.87,1372.87 913.121,1372.87 921.373,1372.87 929.624,1372.87 937.876,1372.87 946.127,1372.87 954.379,1372.87 962.63,1372.87 970.882,1372.87 \n",
       "  979.133,1372.87 987.385,1372.87 995.636,1372.87 1003.89,1372.87 1012.14,1372.87 1020.39,1372.87 1028.64,1372.87 1036.89,1372.87 1045.14,1372.87 1053.4,1372.87 \n",
       "  1061.65,1372.87 1069.9,1372.87 1078.15,1372.87 1086.4,1372.87 1094.65,1372.87 1102.91,1372.87 1111.16,1372.87 1119.41,1372.87 1127.66,1372.87 1135.91,1372.87 \n",
       "  1144.16,1372.87 1152.41,1372.87 1160.67,1372.87 1168.92,1372.87 1177.17,1372.87 1185.42,1372.87 1193.67,1372.87 1201.92,1372.87 1210.17,1372.87 1218.43,1372.87 \n",
       "  1226.68,1372.87 1234.93,1372.87 1243.18,1372.87 1251.43,1372.87 1259.68,1372.87 1267.93,1366.02 1276.19,1352.34 1284.44,1338.66 1292.69,1324.97 1300.94,1311.29 \n",
       "  1309.19,1297.6 1317.44,1283.92 1325.7,1270.23 1333.95,1256.55 1342.2,1242.86 1350.45,1229.18 1358.7,1215.49 1366.95,1201.81 1375.2,1188.13 1383.46,1174.44 \n",
       "  1391.71,1160.76 1399.96,1147.07 1408.21,1133.39 1416.46,1119.7 1424.71,1106.02 1432.96,1092.33 1441.22,1078.65 1449.47,1064.97 1457.72,1051.28 1465.97,1037.6 \n",
       "  1474.22,1023.91 1482.47,1010.23 1490.72,996.543 1498.98,982.858 1507.23,969.174 1515.48,955.489 1523.73,941.805 1531.98,928.12 1540.23,914.436 1548.48,900.751 \n",
       "  1556.74,887.067 1564.99,873.382 1573.24,859.698 1581.49,846.013 1589.74,832.329 1597.99,818.644 1606.25,804.96 1614.5,791.276 1622.75,777.591 1631,763.907 \n",
       "  1639.25,750.222 1647.5,736.538 1655.75,722.853 1664.01,709.169 1672.26,695.484 1680.51,681.8 1688.76,668.115 1697.01,654.431 1705.26,640.746 1713.51,627.062 \n",
       "  1721.77,613.377 1730.02,599.693 1738.27,586.008 1746.52,572.324 1754.77,558.639 1763.02,544.955 1771.27,531.27 1779.53,517.586 1787.78,503.901 1796.03,490.217 \n",
       "  1804.28,476.532 1812.53,462.848 1820.78,449.163 1829.03,435.479 1837.29,421.794 1845.54,408.11 1853.79,394.425 1862.04,380.741 1870.29,367.056 1878.54,353.372 \n",
       "  1886.8,339.687 1895.05,326.003 1903.3,312.318 1911.55,298.634 1919.8,284.949 1928.05,271.265 1936.3,257.58 1944.56,243.896 1952.81,230.211 1961.06,216.527 \n",
       "  1969.31,202.842 1977.56,189.158 1985.81,175.473 1994.06,161.789 2002.32,148.104 2010.57,134.42 2018.82,120.735 2027.07,107.051 2035.32,93.3662 2043.57,79.6817 \n",
       "  2051.82,65.9972 2060.08,52.3127 2068.33,38.6283 2076.58,24.9438 2084.83,11.2593 2093.08,-2.42523 2101.33,-16.1097 2109.58,-29.7942 2117.84,-43.4787 2126.09,-57.1632 \n",
       "  2134.34,-70.8477 2142.59,-84.5322 2150.84,-98.2167 2159.09,-111.901 2167.35,-125.586 2175.6,-139.27 2183.85,-152.955 2192.1,-166.639 2200.35,-180.324 2208.6,-194.008 \n",
       "  2216.85,-207.693 2225.11,-221.377 2233.36,-235.062 2241.61,-248.746 2249.86,-262.431 2258.11,-276.115 2266.36,-289.8 2274.61,-303.484 2282.87,-317.169 2291.12,-330.853 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0500)\" d=\"\n",
       "M246.862 448.912 L648.782 448.912 L648.782 206.992 L246.862 206.992  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  246.862,448.912 648.782,448.912 648.782,206.992 246.862,206.992 246.862,448.912 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  270.862,267.472 414.862,267.472 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0500)\" d=\"M 0 0 M461.107 251.326 L461.107 255.887 Q458.445 254.613 456.084 253.988 Q453.723 253.363 451.524 253.363 Q447.705 253.363 445.621 254.845 Q443.561 256.326 443.561 259.058 Q443.561 261.349 444.927 262.53 Q446.316 263.687 450.158 264.405 L452.982 264.984 Q458.214 265.979 460.691 268.502 Q463.191 271.002 463.191 275.215 Q463.191 280.238 459.811 282.831 Q456.455 285.423 449.95 285.423 Q447.496 285.423 444.718 284.868 Q441.964 284.312 439.001 283.224 L439.001 278.41 Q441.848 280.007 444.58 280.817 Q447.311 281.627 449.95 281.627 Q453.955 281.627 456.13 280.053 Q458.306 278.479 458.306 275.562 Q458.306 273.016 456.732 271.581 Q455.181 270.146 451.617 269.428 L448.769 268.873 Q443.538 267.831 441.2 265.609 Q438.862 263.386 438.862 259.428 Q438.862 254.845 442.08 252.206 Q445.32 249.567 450.992 249.567 Q453.422 249.567 455.945 250.007 Q458.468 250.447 461.107 251.326 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M471.871 251.465 L471.871 258.826 L480.644 258.826 L480.644 262.137 L471.871 262.137 L471.871 276.211 Q471.871 279.382 472.728 280.285 Q473.607 281.187 476.269 281.187 L480.644 281.187 L480.644 284.752 L476.269 284.752 Q471.339 284.752 469.464 282.923 Q467.589 281.072 467.589 276.211 L467.589 262.137 L464.464 262.137 L464.464 258.826 L467.589 258.826 L467.589 251.465 L471.871 251.465 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M507.288 270.724 L507.288 272.808 L487.704 272.808 Q487.982 277.206 490.343 279.521 Q492.727 281.812 496.964 281.812 Q499.417 281.812 501.709 281.21 Q504.024 280.609 506.292 279.405 L506.292 283.433 Q504.001 284.405 501.593 284.914 Q499.186 285.423 496.709 285.423 Q490.505 285.423 486.871 281.812 Q483.26 278.201 483.26 272.044 Q483.26 265.678 486.686 261.951 Q490.135 258.201 495.968 258.201 Q501.2 258.201 504.232 261.581 Q507.288 264.937 507.288 270.724 M503.028 269.474 Q502.982 265.979 501.061 263.896 Q499.163 261.812 496.014 261.812 Q492.45 261.812 490.297 263.826 Q488.167 265.84 487.843 269.498 L503.028 269.474 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M515.876 280.863 L515.876 294.613 L511.593 294.613 L511.593 258.826 L515.876 258.826 L515.876 262.762 Q517.218 260.447 519.255 259.336 Q521.315 258.201 524.162 258.201 Q528.885 258.201 531.824 261.951 Q534.787 265.701 534.787 271.812 Q534.787 277.923 531.824 281.673 Q528.885 285.423 524.162 285.423 Q521.315 285.423 519.255 284.312 Q517.218 283.178 515.876 280.863 M530.366 271.812 Q530.366 267.113 528.422 264.451 Q526.5 261.766 523.121 261.766 Q519.741 261.766 517.797 264.451 Q515.876 267.113 515.876 271.812 Q515.876 276.511 517.797 279.197 Q519.741 281.859 523.121 281.859 Q526.5 281.859 528.422 279.197 Q530.366 276.511 530.366 271.812 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip0500)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  270.862,327.952 414.862,327.952 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0500)\" d=\"M 0 0 M461.107 311.806 L461.107 316.367 Q458.445 315.093 456.084 314.468 Q453.723 313.843 451.524 313.843 Q447.705 313.843 445.621 315.325 Q443.561 316.806 443.561 319.538 Q443.561 321.829 444.927 323.01 Q446.316 324.167 450.158 324.885 L452.982 325.464 Q458.214 326.459 460.691 328.982 Q463.191 331.482 463.191 335.695 Q463.191 340.718 459.811 343.311 Q456.455 345.903 449.95 345.903 Q447.496 345.903 444.718 345.348 Q441.964 344.792 439.001 343.704 L439.001 338.89 Q441.848 340.487 444.58 341.297 Q447.311 342.107 449.95 342.107 Q453.955 342.107 456.13 340.533 Q458.306 338.959 458.306 336.042 Q458.306 333.496 456.732 332.061 Q455.181 330.626 451.617 329.908 L448.769 329.353 Q443.538 328.311 441.2 326.089 Q438.862 323.866 438.862 319.908 Q438.862 315.325 442.08 312.686 Q445.32 310.047 450.992 310.047 Q453.422 310.047 455.945 310.487 Q458.468 310.927 461.107 311.806 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M467.658 319.306 L471.917 319.306 L471.917 345.232 L467.658 345.232 L467.658 319.306 M467.658 309.214 L471.917 309.214 L471.917 314.607 L467.658 314.607 L467.658 309.214 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M493.445 331.968 Q493.445 327.339 491.524 324.792 Q489.626 322.246 486.177 322.246 Q482.751 322.246 480.829 324.792 Q478.931 327.339 478.931 331.968 Q478.931 336.575 480.829 339.121 Q482.751 341.667 486.177 341.667 Q489.626 341.667 491.524 339.121 Q493.445 336.575 493.445 331.968 M497.704 342.015 Q497.704 348.635 494.765 351.852 Q491.825 355.093 485.76 355.093 Q483.515 355.093 481.524 354.746 Q479.533 354.422 477.658 353.727 L477.658 349.584 Q479.533 350.602 481.362 351.089 Q483.19 351.575 485.089 351.575 Q489.278 351.575 491.362 349.376 Q493.445 347.2 493.445 342.778 L493.445 340.672 Q492.126 342.964 490.065 344.098 Q488.005 345.232 485.135 345.232 Q480.366 345.232 477.45 341.598 Q474.533 337.964 474.533 331.968 Q474.533 325.95 477.45 322.316 Q480.366 318.681 485.135 318.681 Q488.005 318.681 490.065 319.816 Q492.126 320.95 493.445 323.242 L493.445 319.306 L497.704 319.306 L497.704 342.015 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M522.357 324.283 Q523.954 321.413 526.176 320.047 Q528.399 318.681 531.408 318.681 Q535.459 318.681 537.658 321.529 Q539.857 324.353 539.857 329.584 L539.857 345.232 L535.574 345.232 L535.574 329.723 Q535.574 325.996 534.255 324.191 Q532.936 322.385 530.227 322.385 Q526.917 322.385 524.996 324.584 Q523.075 326.783 523.075 330.579 L523.075 345.232 L518.792 345.232 L518.792 329.723 Q518.792 325.973 517.473 324.191 Q516.153 322.385 513.399 322.385 Q510.135 322.385 508.214 324.607 Q506.292 326.806 506.292 330.579 L506.292 345.232 L502.01 345.232 L502.01 319.306 L506.292 319.306 L506.292 323.334 Q507.751 320.95 509.788 319.816 Q511.825 318.681 514.626 318.681 Q517.45 318.681 519.417 320.117 Q521.408 321.552 522.357 324.283 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M554.371 322.292 Q550.945 322.292 548.954 324.978 Q546.963 327.64 546.963 332.292 Q546.963 336.945 548.931 339.63 Q550.922 342.292 554.371 342.292 Q557.773 342.292 559.764 339.607 Q561.755 336.922 561.755 332.292 Q561.755 327.686 559.764 325.001 Q557.773 322.292 554.371 322.292 M554.371 318.681 Q559.926 318.681 563.097 322.292 Q566.269 325.904 566.269 332.292 Q566.269 338.658 563.097 342.292 Q559.926 345.903 554.371 345.903 Q548.792 345.903 545.621 342.292 Q542.473 338.658 542.473 332.292 Q542.473 325.904 545.621 322.292 Q548.792 318.681 554.371 318.681 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M570.736 319.306 L574.996 319.306 L574.996 345.232 L570.736 345.232 L570.736 319.306 M570.736 309.214 L574.996 309.214 L574.996 314.607 L570.736 314.607 L570.736 309.214 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M596.523 323.242 L596.523 309.214 L600.782 309.214 L600.782 345.232 L596.523 345.232 L596.523 341.343 Q595.181 343.658 593.12 344.792 Q591.083 345.903 588.213 345.903 Q583.514 345.903 580.551 342.153 Q577.611 338.403 577.611 332.292 Q577.611 326.181 580.551 322.431 Q583.514 318.681 588.213 318.681 Q591.083 318.681 593.12 319.816 Q595.181 320.927 596.523 323.242 M582.009 332.292 Q582.009 336.991 583.931 339.677 Q585.875 342.339 589.255 342.339 Q592.634 342.339 594.579 339.677 Q596.523 336.991 596.523 332.292 Q596.523 327.593 594.579 324.931 Q592.634 322.246 589.255 322.246 Q585.875 322.246 583.931 324.931 Q582.009 327.593 582.009 332.292 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip0500)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  270.862,388.432 414.862,388.432 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0500)\" d=\"M 0 0 M455.251 389.509 Q456.755 390.018 458.167 391.684 Q459.603 393.351 461.038 396.268 L465.783 405.712 L460.76 405.712 L456.339 396.846 Q454.626 393.374 453.005 392.24 Q451.408 391.106 448.63 391.106 L443.538 391.106 L443.538 405.712 L438.862 405.712 L438.862 371.152 L449.418 371.152 Q455.343 371.152 458.26 373.629 Q461.177 376.106 461.177 381.106 Q461.177 384.37 459.649 386.522 Q458.144 388.675 455.251 389.509 M443.538 374.995 L443.538 387.263 L449.418 387.263 Q452.797 387.263 454.51 385.712 Q456.246 384.138 456.246 381.106 Q456.246 378.073 454.51 376.546 Q452.797 374.995 449.418 374.995 L443.538 374.995 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M490.297 391.684 L490.297 393.768 L470.714 393.768 Q470.991 398.166 473.353 400.481 Q475.737 402.772 479.973 402.772 Q482.427 402.772 484.718 402.17 Q487.033 401.569 489.302 400.365 L489.302 404.393 Q487.01 405.365 484.603 405.874 Q482.195 406.383 479.718 406.383 Q473.515 406.383 469.88 402.772 Q466.269 399.161 466.269 393.004 Q466.269 386.638 469.695 382.911 Q473.144 379.161 478.978 379.161 Q484.209 379.161 487.241 382.541 Q490.297 385.897 490.297 391.684 M486.038 390.434 Q485.991 386.939 484.07 384.856 Q482.172 382.772 479.024 382.772 Q475.459 382.772 473.306 384.786 Q471.177 386.8 470.853 390.458 L486.038 390.434 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M494.95 371.152 L499.626 371.152 L499.626 401.777 L516.454 401.777 L516.454 405.712 L494.95 405.712 L494.95 371.152 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip0500)\" d=\"M 0 0 M518.213 371.152 L522.913 371.152 L522.913 392.147 Q522.913 397.703 524.926 400.157 Q526.94 402.587 531.454 402.587 Q535.945 402.587 537.959 400.157 Q539.973 397.703 539.973 392.147 L539.973 371.152 L544.672 371.152 L544.672 392.726 Q544.672 399.485 541.315 402.934 Q537.982 406.383 531.454 406.383 Q524.903 406.383 521.547 402.934 Q518.213 399.485 518.213 392.726 L518.213 371.152 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=range(-5,stop=5,length=250)\n",
    "ystp=step_function(x)\n",
    "ysig=sigmoid(x)\n",
    "yrel=relu(x)\n",
    "plot(x, ystp, title=\"Activation function\", label=\"Step\",\n",
    "    ylims=(-0.1,1.1), legend=:topleft)\n",
    "plot!(x, ysig,label=\"Sigmoid\")\n",
    "plot!(x, yrel,label=\"ReLU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망에서 비선형 함수만 활성화 함수로 사용하는 이유\n",
    "\n",
    "선형 함수인 $h(x)=cx$를 활성화함수로 사용하여 3층의 신경망을 만들 경우\n",
    "\n",
    "$$y(x)=h(h(h(x)))=c*c*c*x=ax$$\n",
    "\n",
    "이와 같이 $a=c^3$인 $y(x)=ax$가 되므로 신경망의 층을 깊게 하는 의미가 없게 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2; 3 4; 5 6"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×2 Array{Int64,2}:\n",
       " 1  2\n",
       " 3  4\n",
       " 5  6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]"
     ]
    }
   ],
   "source": [
    "# 다차원 배열\n",
    "B = [[1 2];[3 4];[5 6]]\n",
    "print(B)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Int64,2}:\n",
       " 19  22\n",
       " 43  50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [[1 2];[3 4]]\n",
    "B = [[5 6];[7 8]]\n",
    "A*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 23\n",
       " 53\n",
       " 83"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [[1 2];[3 4];[5 6]]\n",
    "B = [7,8]    # [7 8] 이라고 하면 1×2 , [7,8] 이라고 해야 2×1\n",
    "A*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×3 Array{Int64,2}:\n",
       " 5  11  17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x₁,x₂에서 y₁,y₂,y₃로 가는 신경망\n",
    "X=[1 2]      # X : 1×2 ,  W : 2×3\n",
    "W=[[1 3 5];[2 4 6]]\n",
    "X*W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2개의 input, 2개의 output과 3개의 1층 은닉노드, 2개의 2층 은닉노드가 있는 경우.\n",
    "\n",
    "입력노드 $x_i$에서 1층의 은닉노드 $a_j^{(1)}$로 향하는 가중치를 표기할 때,\n",
    "$$w_{j\\; i}^{(1)}$$\n",
    "라고 표기한다. 하첨자에 다음층에서의 순번과 이전층에서의 순번, 윗첨자에 다음층의 층 번호를 기입한다.\n",
    "\n",
    "1층의 첫번째 은닉노드가 가지는 값은 다음이 된다.\n",
    "\n",
    "$$a_1^{(1)}=w_{11}^{(1)}x_1+w_{12}^{(1)}x_2+b^{(1)}$$\n",
    "\n",
    "1층의 모든 은닉노드가 가지는 값을 행렬연산으로 나타낼 수도 있다.\n",
    "\n",
    "$$A^{(1)}=XW^{(1)}+B^{(1)}$$\n",
    "\n",
    "각 행렬은 다음을 뜻한다.\n",
    "\n",
    "$$A^{(1)}=[a_1^{(1)} \\: a_2^{(1)} \\: a_3^{(1)}],\\;\n",
    "B^{(1)}=[b_1^{(1)} \\: b_2^{(1)} \\: b_3^{(1)}]$$\n",
    "\n",
    "$$X^{(1)}=[x_1 \\: x_2],\\; \n",
    "W^{(1)}=\\begin{bmatrix} w_{11}^{(1)}&w_{21}^{(1)}&w_{31}^{(1)} \\\\ \n",
    "w_{12}^{(1)}&w_{22}^{(1)}&w_{32}^{(1)} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(1, 2)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×3 Array{Float64,2}:\n",
       " 0.3  0.7  1.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 식을 코드로 구현\n",
    "\n",
    "X=[1.0 0.5]\n",
    "W1 = [[0.1 0.3 0.5];[0.2 0.4 0.6]]\n",
    "B1 = [0.1 0.2 0.3]\n",
    "\n",
    "println(size(W1))\n",
    "println(size(X))\n",
    "println(size(B1))\n",
    "\n",
    "A1 = X*W1 + B1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "활성화함수를 이용해 $Z_1 = h(A_1)$를 만들도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×3 Array{Float64,2}:\n",
       " 0.574443  0.668188  0.75026"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1 = sigmoid(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(3, 2)\n",
      "(1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×2 Array{Float64,2}:\n",
       " 0.626249  0.771011"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력층-1층에 이어 1층-2층 구현.\n",
    "W2 = [[0.1 0.4];[0.2 0.5];[0.3 0.6]]\n",
    "B2 = [0.1 0.2]\n",
    "\n",
    "println(size(Z1))\n",
    "println(size(W2))\n",
    "println(size(B2))\n",
    "\n",
    "A2 = Z1*W2 + B2\n",
    "Z2 = sigmoid(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Array{Float64,2}:\n",
       " 0.316827  0.696279"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2층-출력층\n",
    "function identity_function(x)   # 코드 구조 통일을 위해 항등함수 정의\n",
    "    return x\n",
    "end\n",
    "\n",
    "W3 = [[0.1 0.3];[0.2 0.4]]\n",
    "B3 = [0.1 0.2]\n",
    "\n",
    "A3 = Z2*W3 + B3\n",
    "Y = identity_function(A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward (generic function with 2 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3층 신경망을 함수로 구현\n",
    "\n",
    "function init_network()     # 가중치,편향 초기값\n",
    "    network = Dict()\n",
    "    network[\"W1\"]=[[0.1 0.3 0.5];[0.2 0.4 0.6]]\n",
    "    network[\"b1\"]=[0.1 0.2 0.3]\n",
    "    network[\"W2\"]=[[0.1 0.4];[0.2 0.5];[0.3 0.6]]\n",
    "    network[\"b2\"]=[0.1 0.2]\n",
    "    network[\"W3\"]=[[0.1 0.3];[0.2 0.4]]\n",
    "    network[\"b3\"]=[0.1 0.2]\n",
    "    return network\n",
    "end\n",
    "\n",
    "function forward(network, x, actfunction = relu)\n",
    "    W1,W2,W3 = network[\"W1\"],network[\"W2\"],network[\"W3\"]\n",
    "    b1,b2,b3 = network[\"b1\"],network[\"b2\"],network[\"b3\"]\n",
    "    \n",
    "    a1 = x*W1 + b1\n",
    "    z1 = actfunction(a1)\n",
    "    a2 = z1*W2 + b2\n",
    "    z2 = actfunction(a2)\n",
    "    a3 = z2*W3 + b3\n",
    "    y = identity_function(a3)\n",
    "    \n",
    "    return y\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3168270764110298 0.6962790898619668]"
     ]
    }
   ],
   "source": [
    "network = init_network()\n",
    "x = [1.0 0.5]\n",
    "y = forward(network,x,sigmoid)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 출력층 설계\n",
    "\n",
    "마지막 layer의 활성화 함수에 따라 회귀 및 분류모델이 된다.\n",
    "\n",
    "회귀모델에서는 지금까지 해온 것과 같이 $y_i=a_i$로 표현되는 항등함수를 사용하는 것이 일반적이고, 분류모델은 Softmax 함수를 사용한다.\n",
    "\n",
    "$$y_k=\\frac{exp(a_k)}{\\sum_{i=1}^n exp(a_i)}$$\n",
    "\n",
    "도식으로 표현할땐 마지막 은닉층에서 모든 화살표가 출력층으로 가게 된다. 항등함수와 달리 각 은닉노드가 모두 영향을 주기 때문.\n",
    "\n",
    "딥러닝 분류모델에서 결과값의 대소관계는 Softmax를 거치나 안거치나 똑같기때문에, 훈련할때에는 Softmax를 사용하지만, 추론할때는 생략하고 가장 큰 값만 파악하여 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function softmax(a)\n",
    "    exp_a = map(i -> exp(i), a)\n",
    "    sum_exp_a = sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax에서 오버플로우를 막는 방법\n",
    "\n",
    "exponential 연산은 출력값이 매우 크게 될 수도 있으므로(예를 들어 $e^{10}=22026$, $e^{20}=485165195$) 컴퓨터의 표현 한계를 뛰어넘을 수도 있게 된다. 그러한 값들로 나눗셈을 하면 결과값도 불안정해진다.\n",
    "$$  y_k=\\frac{C\\,exp(a_k)}{C\\sum_{n=i}^n exp(a_i)} = \\frac{exp(a_k+log\\,C)}{\\sum_{n=i}^n exp(a_i+log\\,C)} \n",
    "=\\frac{exp(a_k+C')}{\\sum_{n=i}^n exp(a_i+C')} $$\n",
    "\n",
    "$C'$은 아무 값이나 넣어도 성립한다. 보통 입력신호 중 최댓값을 음수로 하여 투입하는게 일반적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overflow 방지처리된 Softmax 함수\n",
    "function softmax(a)\n",
    "    c = maximum(a)\n",
    "    exp_a = map(i -> exp(i-c), a)\n",
    "    sum_exp_a = sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = Data.MNIST.images()\n",
    "#y_train = Data.MNIST.labels()\n",
    "#X_test = Data.MNIST.images(:test)\n",
    "#y_test = Data.MNIST.labels(:test)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (60000,) (10000,) (10000,)"
     ]
    }
   ],
   "source": [
    "#print(size(X_train),\" \",size(y_train),\" \",size(X_test),\" \",size(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(784,)"
     ]
    }
   ],
   "source": [
    "#Xtr = map(i -> reshape(i,784), X_train)\n",
    "#Xte = map(i -> reshape(i,784), X_test)\n",
    "#println(size(X_train[1]));print(size(Xtr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getpickle (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyCall 기능을 통해 파이썬용으로 만들어진 pkl파일을 가져온다.\n",
    "function getpickle(filename)\n",
    "    r = nothing\n",
    "    @pywith pybuiltin(\"open\")(filename,\"rb\") as f begin\n",
    "        r = pickle.load(f)\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 0, 4, 1, 9, 2, 1, 3, 1, 4  …  9, 2, 9, 5, 1, 8, 3, 5, 6, 8], [7, 2, 1, 0, 4, 1, 4, 9, 5, 9  …  7, 8, 9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", version=1)\n",
    "pyX, pyy = mnist[\"data\"]/255, mnist[\"target\"]\n",
    "pyy = np.array(pyy)\n",
    "pyy = [parse(Int, x) for x in pyy]\n",
    "pyX_train,pyX_test=pyX[begin:60000,:],pyX[60001:end,:]\n",
    "pyy_train,pyy_test=pyy[begin:60000],pyy[60001:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 2 methods)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_network()\n",
    "    network = getpickle(\"C:\\\\Users\\\\Sunmo Koo\\\\Desktop\\\\Data\\\\sample_weight.pkl\")\n",
    "    return network\n",
    "end\n",
    "\n",
    "function predict(network, x, actfunc = sigmoid)\n",
    "    W1,W2,W3 = network[\"W1\"],network[\"W2\"],network[\"W3\"]\n",
    "    b1,b2,b3 = network[\"b1\"],network[\"b2\"],network[\"b3\"]\n",
    "    \n",
    "    xt = transpose(convert(Array{Float32},x))\n",
    "    a1 = xt*W1 + transpose(b1)\n",
    "    z1 = actfunc(a1)\n",
    "    a2 = z1*W2 + transpose(b2)\n",
    "    z2 = actfunc(a2)\n",
    "    a3 = z2*W3 + transpose(b3)\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 6 entries:\n",
       "  \"W2\" => Float32[-0.10694 0.0159125 … 0.14046 0.0396424; 0.299116 -0.0332223 ……\n",
       "  \"W3\" => Float32[-0.421736 0.689445 … -0.305001 0.0275985; -0.524321 -0.143625…\n",
       "  \"b3\" => Float32[-0.0602398, 0.00932628, -0.0135995, 0.0216713, 0.0107372, 0.0…\n",
       "  \"b2\" => Float32[-0.0147111, -0.0721513, -0.00155692, 0.121997, 0.116033, -0.0…\n",
       "  \"W1\" => Float32[-0.00741249 -0.00790439 … -0.0433127 -0.013501; -0.0102975 -0…\n",
       "  \"b1\" => Float32[-0.0675032, 0.0695926, -0.0273047, 0.0225609, -0.220015, -0.2…"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = init_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: y_test not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: y_test not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[21]:5"
     ]
    }
   ],
   "source": [
    "accuracy_cnt = 0\n",
    "for i in 1:size(pyX_test)[1]\n",
    "    y = predict(network, pyX_test[i,:])\n",
    "    p = findall(a->a==maximum(y),y)[1][2]-1   # 가장 확률이 높은 인덱스\n",
    "    if p == y_test[i]\n",
    "        accuracy_cnt += 1\n",
    "    end\n",
    "end\n",
    "print(\"Accuracy : \",accuracy_cnt/size(pyX_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "function multi_append(b,N)\n",
    "    bt=transpose(b)\n",
    "    bb=bt\n",
    "    for i in 1:N-1\n",
    "        bb=[bb;bt]\n",
    "    end\n",
    "    return bb\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 2 methods)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(network, x, actfunc = sigmoid)\n",
    "    W1,W2,W3 = network[\"W1\"],network[\"W2\"],network[\"W3\"]\n",
    "    b1,b2,b3 = network[\"b1\"],network[\"b2\"],network[\"b3\"]\n",
    "\n",
    "    a1 = x*W1 + multi_append(b1,100)\n",
    "    z1 = actfunc(a1)\n",
    "    a2 = z1*W2 + multi_append(b2,100)\n",
    "    z2 = actfunc(a2)\n",
    "    a3 = z2*W3 + multi_append(b3,100)\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 2\n",
      "p : 7\n",
      "p : 7\n",
      "p : 7\n",
      "p : 7\n",
      "p : 7\n",
      "p : 7\n",
      "p : 0\n",
      "p : 0\n",
      "p : 0\n",
      "p : 0\n",
      "p : 0\n",
      "p : 0\n",
      "p : 0\n",
      "p : 0\n",
      "p : 0\n",
      "p : 0\n",
      "p : 0\n",
      "Accuracy : 0.0"
     ]
    }
   ],
   "source": [
    "# 배치처리\n",
    "batch_size = 100\n",
    "accuracy_cnt = 0\n",
    "batches = range(1,length=convert(Int32,size(pyX_test)[1]/batch_size),batch_size)\n",
    "\n",
    "for i in map(a->convert(Int32,a),batches)\n",
    "    x_batch = pyX_test[i:i+batch_size-1,:]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = findall(a->a==maximum(y_batch),y_batch)[1][2]-1\n",
    "    println(\"p : \",p)\n",
    "    accuracy_cnt += sum(p==pyy_test[i:i+batch_size-1])\n",
    "end\n",
    "\n",
    "print(\"Accuracy : \",accuracy_cnt/size(pyX_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionMismatch",
     "evalue": "DimensionMismatch(\"dimensions must match: a has dims (Base.OneTo(100), Base.OneTo(50)), b has dims (Base.OneTo(1), Base.OneTo(50)), mismatch at 1\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"dimensions must match: a has dims (Base.OneTo(100), Base.OneTo(50)), b has dims (Base.OneTo(1), Base.OneTo(50)), mismatch at 1\")",
      "",
      "Stacktrace:",
      " [1] promote_shape at .\\indices.jl:178 [inlined]",
      " [2] promote_shape at .\\indices.jl:169 [inlined]",
      " [3] +(::Array{Float64,2}, ::Transpose{Float32,Array{Float32,1}}) at .\\arraymath.jl:38",
      " [4] predict(::Dict{Any,Any}, ::Array{Float64,2}, ::typeof(sigmoid)) at .\\In[22]:5",
      " [5] predict(::Dict{Any,Any}, ::Array{Float64,2}) at .\\In[22]:2",
      " [6] top-level scope at In[25]:2"
     ]
    }
   ],
   "source": [
    "x_batch = pyX_test[1:1+batch_size-1,:]\n",
    "y_batch = predict(network, x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×784 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱                 ⋮              \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×10 Array{Float64,2}:\n",
       " 1.44285e-6   1.42872e-8   7.84577e-7   …  4.78074e-7  2.91446e-6\n",
       " 5.94693e-6   6.00159e-7   0.00052239      1.34251e-6  1.31648e-10\n",
       " 4.1514e-9    1.55941e-5   8.43435e-7      1.24571e-6  5.51776e-8\n",
       " 0.00241899   2.10576e-10  2.51778e-6      2.14696e-7  1.64344e-7\n",
       " 1.27028e-7   1.70277e-8   1.79723e-6      2.6471e-7   1.61991e-6\n",
       " 1.33018e-9   2.85794e-5   8.2882e-7    …  2.68044e-6  1.02862e-7\n",
       " 2.62748e-8   9.99067e-9   4.88558e-9      6.43519e-6  9.54922e-6\n",
       " 4.59226e-9   5.05759e-7   7.70315e-8      3.58883e-6  5.00809e-6\n",
       " 2.77803e-6   1.88797e-8   5.5126e-6       5.02947e-7  2.14545e-8\n",
       " 1.39167e-7   2.32062e-9   6.18706e-9      6.77085e-6  0.00012585\n",
       " 0.00128613   7.23248e-10  5.66024e-6   …  7.03151e-7  6.90273e-9\n",
       " 2.30626e-7   2.889e-7     7.14325e-6      1.19167e-6  8.983e-9\n",
       " 4.79518e-8   3.59315e-8   3.96053e-8      6.57767e-7  2.23173e-5\n",
       " ⋮                                      ⋱              \n",
       " 3.44597e-7   3.56484e-8   0.000106227     2.77551e-8  3.47887e-9\n",
       " 4.74676e-10  4.99085e-5   2.19405e-6      8.89498e-6  2.15497e-8\n",
       " 5.05479e-7   1.93206e-7   1.16266e-7   …  1.86556e-6  1.63657e-6\n",
       " 2.5316e-8    1.1569e-6    3.82272e-6      4.96567e-7  7.25356e-9\n",
       " 2.12902e-8   2.87387e-7   2.13666e-7      1.44237e-6  1.47413e-6\n",
       " 1.25039e-7   3.571e-7     3.27327e-8      2.82538e-6  2.37962e-6\n",
       " 7.42775e-11  0.000123627  5.367e-7        1.09614e-5  4.90765e-8\n",
       " 6.19019e-9   6.20792e-8   6.31632e-7   …  4.35343e-6  2.0375e-6\n",
       " 2.95205e-9   7.37821e-6   8.91159e-8      8.489e-7    5.57043e-7\n",
       " 1.46241e-9   4.4965e-6    5.96442e-7      1.38074e-6  3.44588e-7\n",
       " 2.72045e-6   9.32315e-8   1.02662e-5      2.40158e-7  9.60305e-10\n",
       " 2.42813e-9   5.07623e-8   7.51583e-7      7.45017e-7  9.41857e-5"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1,W2,W3 = network[\"W1\"],network[\"W2\"],network[\"W3\"]\n",
    "b1,b2,b3 = network[\"b1\"],network[\"b2\"],network[\"b3\"]\n",
    "\n",
    "x = x_batch\n",
    "\n",
    "a1 = x*W1 + multi_append(b1,100)\n",
    "z1 = relu(a1)\n",
    "a2 = z1*W2 + multi_append(b2,100)\n",
    "z2 = relu(a2)\n",
    "a3 = z2*W3 + multi_append(b3,100)\n",
    "y = softmax(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Array{Float32,1}:\n",
       " -0.014711079\n",
       " -0.07215131\n",
       " -0.0015569247\n",
       "  0.12199665\n",
       "  0.11603302\n",
       " -0.007549459\n",
       "  0.040854506\n",
       " -0.08496164\n",
       "  0.028980445\n",
       "  0.019972397\n",
       "  0.19770803\n",
       "  0.04365116\n",
       " -0.06518728\n",
       "  ⋮\n",
       "  0.047371626\n",
       " -0.043627564\n",
       "  0.07450858\n",
       "  0.050779518\n",
       "  0.06648835\n",
       "  0.040640015\n",
       " -0.002651626\n",
       "  0.005768055\n",
       " -0.09652461\n",
       " -0.051313136\n",
       "  0.021996874\n",
       " -0.043586075"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2# + multi_append(b1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size(x*W1) (100,50)\n",
    "size(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Array{Int64,2}:\n",
       " 1  2  3\n",
       " 2  3  4"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1 2 3 ; 2 3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionMismatch",
     "evalue": "DimensionMismatch(\"mismatch in dimension 1 (expected 2 got 1)\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"mismatch in dimension 1 (expected 2 got 1)\")",
      "",
      "Stacktrace:",
      " [1] _cs at .\\abstractarray.jl:1420 [inlined]",
      " [2] _cshp at .\\abstractarray.jl:1416 [inlined]",
      " [3] cat_shape(::Tuple{Bool,Bool}, ::Tuple{Int64,Int64}, ::Tuple{Int64}, ::Tuple{Int64}) at .\\abstractarray.jl:1395 (repeats 2 times)",
      " [4] _cat_t(::Val{2}, ::Type{T} where T, ::Array{Int64,2}, ::Vararg{Any,N} where N) at .\\abstractarray.jl:1440",
      " [5] cat_t(::Type{Int64}, ::Array{Int64,2}, ::Vararg{Any,N} where N; dims::Val{2}) at .\\abstractarray.jl:1437",
      " [6] _cat at .\\abstractarray.jl:1435 [inlined]",
      " [7] #cat#110 at .\\abstractarray.jl:1564 [inlined]",
      " [8] hcat(::Array{Int64,2}, ::Int64, ::Int64) at .\\abstractarray.jl:1544",
      " [9] top-level scope at In[127]:1"
     ]
    }
   ],
   "source": [
    "[([1 2 3 ; 2 3 4]*[1 2 ; 3 4 ; 5 6]) 1 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_append (generic function with 1 method)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function multi_append(b,N)\n",
    "    bt=transpose(b)\n",
    "    bb=bt\n",
    "    for i in 1:N-1\n",
    "        bb=[bb;bt]\n",
    "    end\n",
    "    return bb\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×50 Array{Float32,2}:\n",
       " -0.0675032  0.0695926  -0.0273047  …  0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047  …  0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047  …  0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       "  ⋮                                 ⋱                        \n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047  …  0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047  …  0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168\n",
       " -0.0675032  0.0695926  -0.0273047     0.0452704  -0.151792  0.107168"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_append(b1,100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
